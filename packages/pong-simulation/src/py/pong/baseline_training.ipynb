{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To create a virtual environment and install dependencies, run: `pants venv`. This creates a virtual environment with all the needed deps. Then activate the virtual environment by runnin `dist/export/python/virtualenvs/python-default/3.8.16/bin/source`.\n",
        "\n",
        "The next few blocks set-up python paths on dependent modules and imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(\"../../schemas/gen/py\")\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gym.wrappers import TimeLimit\n",
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.ppo.policies import MultiInputPolicy\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common import results_plotter\n",
        "from tqdm.rich import trange\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "from pong.env.rewards import RewardConfig\n",
        "from pong.env.pong_env import PongEnv, EnvConfig, PaddleConfig\n",
        "from pong.env.opponent import StaticOpponent, ModelOpponent\n",
        "from pong.env.spaces import ActionType\n",
        "from pong.renderer.pygame_renderer import PygameRenderer\n",
        "from pong.renderer.event_renderer import EventRenderer, FileEventWriter\n",
        "import pong.services.evaluation_runner import EvaluationRunner, WrappedEnv\n",
        "from pong.simulation.config import SimulationConfig\n",
        "from pong.env.additional_logs_callback import AdditionalLogsCallback\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Shared variables and utils\n",
        "Execute this block to allow partial execution of the notebook from a cell bellow\n",
        "\n",
        "### Baseline player config\n",
        "\n",
        "The baseline player has genome attributes that puts it at an advantage over most other as we want a good performing agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Shared variables and configurations that could be used downstream. We co-locate these so this block could be executed\n",
        "# and partial execution from a cell bellow works.\n",
        "\n",
        "width = 800\n",
        "height = 400\n",
        "\n",
        "# Change this to use a clean output dir\n",
        "experiment_id = 8\n",
        "experiment = f\"baseline/{experiment_id}\"\n",
        "\n",
        "\n",
        "\n",
        "log_dir = f\".logs/{experiment}\"\n",
        "tb_log_dir = f\".logs/{experiment}_tb\"\n",
        "\n",
        "os.makedirs(experiment, exist_ok = True)\n",
        "os.makedirs(tb_log_dir, exist_ok = True)\n",
        "os.makedirs(f\".models/{experiment}\", exist_ok = True)\n",
        "\n",
        "\n",
        "def pygame_renderer() -> PygameRenderer:\n",
        "    return PygameRenderer(width, height, 60)\n",
        "\n",
        "def model_dir_for(name: str) -> str:\n",
        "    return f\".models/{experiment}/{name}\"\n",
        "\n",
        "def load_model(name: str) -> PPO:\n",
        "    model = PPO.load(model_dir_for(name))\n",
        "    model.tensorboard_log = tb_log_dir\n",
        "    return model\n",
        "\n",
        "def evaluate(model: PPO, env: gym.Env, config: SimulationConfig, iterations = 100):\n",
        "    EvaluationRunner(pygame_renderer).evaluate(model, env, config, 100)\n",
        "    \n",
        "def load_and_evaluate(name: str, env: PongEnv, config: SimulationConfig, iterations = 100):\n",
        "    model = load_model(name)\n",
        "    model.set_env(env)\n",
        "    env.disable_training()\n",
        "\n",
        "    EvaluationRunner(pygame_renderer()).evaluate(model, env, config, 100)\n",
        "    \n",
        "def load_and_evaluate_models(name_l: str, name_r: str, env: PongEnv, config: SimulationConfig, iterations = 100):\n",
        "    model_l = load_model(name_l)\n",
        "    model_r = load_model(name_r)\n",
        "\n",
        "    env.set_opponent(ModelOpponent(model_r))\n",
        "    env.disable_training()\n",
        "    model_l.set_env(env)\n",
        "\n",
        "    EvaluationRunner(pygame_renderer()).evaluate(model_l, env, config, 100)\n",
        "\n",
        "# helper for running the training loop but keep checkpointing along the way\n",
        "def learn(model: PPO, name: str, env: PongEnv, iterations: int):\n",
        "    wrapped = TimeLimit(env, 60 * 60 * 1)\n",
        "    model.set_env(wrapped)\n",
        "    \n",
        "    # store every 10k steps\n",
        "    for r in range(0, iterations, 10_000):\n",
        "        model.learn(total_timesteps=10_000, tb_log_name=name, callback=AdditionalLogsCallback(), reset_num_timesteps=False)\n",
        "        model.save(model_dir_for(name))\n",
        "    \n",
        "    \n",
        "    \n",
        "# =========== Baseline player config ==============\n",
        "# The baseline player has genome attributes that puts it at an advantage over most other as we want a\n",
        "# good performing agent. \n",
        "player_paddle = PaddleConfig(width = 100, strength = 25, endurance=10, max_speed=1000,)\n",
        "\n",
        "# A static paddle that does not move\n",
        "wall_paddle = PaddleConfig(width = 1000, strength = 1000, endurance=3, max_speed=500,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Play against the wall\n",
        "\n",
        "Start with a completely random model and train against a wall as we don't have any other baseline, This way the agents learns to follow the ball and defend on the early stages.\n",
        "Reward for near misses as this is a faster way for the agent to learn to "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "reward_config = RewardConfig(\n",
        "    win_round = 10,\n",
        "    lose_round = -5,\n",
        "    paddle_hit = 5,\n",
        "    near_miss_multiplier = 1,\n",
        "    near_miss_exponent = 5,\n",
        "    near_miss_min_distance = height / 2,\n",
        "    survival_reward_multiplier = 1,\n",
        "    endurance_penalty_multiplier = -1,\n",
        ")\n",
        "\n",
        "play_against_wall_config = EnvConfig(\n",
        "    paddle_l = player_paddle,\n",
        "    paddle_r = wall_paddle,\n",
        "    width = width,\n",
        "    height = height,\n",
        ")\n",
        "\n",
        "play_against_wall_env = PongEnv(play_against_wall_config, reward_config)\n",
        "play_against_wall_env.enable_training()\n",
        "play_against_wall_env.set_opponent(StaticOpponent(ActionType.STOP, 0.0))\n",
        "\n",
        "model = PPO(MultiInputPolicy, play_against_wall_env, verbose=0, device=\"cpu\", tensorboard_log=tb_log_dir, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "learn(model, \"wall_near_miss\", play_against_wall_env, 10_000_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(model_dir_for(\"wall_near_miss\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load_and_evaluate(\"wall_near_miss\", play_against_wall_env, play_against_wall_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Play against itself to improve on defense and learn attacking moves\n",
        "\n",
        "The use the same model to play with it-self. The wall helps to learn defense but does not allow to learn attacking strategies. Lest setup two reward confics so we could get two model behaviors, one model that is rewarded for defense and another to attack."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = load_model(\"wall_near_miss\")\n",
        "\n",
        "# still no reward for winning, we need to defend a moving target first\n",
        "reward_config = RewardConfig(\n",
        "    win_round = -10,\n",
        "    lose_round = -10,\n",
        "    paddle_hit = 5,\n",
        "    near_miss_multiplier = 1,\n",
        "    near_miss_exponent = 5,\n",
        "    near_miss_min_distance = height / 10,\n",
        "    survival_reward_multiplier = 1,\n",
        "    endurance_penalty_multiplier = -1,\n",
        ")\n",
        "\n",
        "env_config = EnvConfig(\n",
        "    paddle_l = player_paddle,\n",
        "    paddle_r = player_paddle,\n",
        "    width = width,\n",
        "    height = height,\n",
        ")\n",
        "\n",
        "self_env = PongEnv(env_config, reward_config)\n",
        "self_env.enable_training()\n",
        "model.set_env(self_env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "opponent = model\n",
        "\n",
        "self_env.set_opponent(ModelOpponent(opponent))\n",
        "learn(model, \"play_against_self_opponent_3\", self_env, 1_000_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(model_dir_for(\"play_against_self_opponent_3\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_and_evaluate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplay_against_self_opponent_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplay_against_self_opponent_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[8], line 50\u001b[0m, in \u001b[0;36mload_and_evaluate_models\u001b[0;34m(name_l, name_r, env, config, iterations)\u001b[0m\n\u001b[1;32m     47\u001b[0m env\u001b[38;5;241m.\u001b[39mdisable_training()\n\u001b[1;32m     48\u001b[0m model_l\u001b[38;5;241m.\u001b[39mset_env(env)\n\u001b[0;32m---> 50\u001b[0m \u001b[43mEvaluationRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygame_renderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/projects/asm/acp-demo/packages/pong-simulation/src/services/evaluation_runner.py:60\u001b[0m, in \u001b[0;36mEvaluationRunner.evaluate\u001b[0;34m(self, model, env, config, iterations)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Render the current state of the simulation, via the environment\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevents\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrewards\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m frame_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     65\u001b[0m result \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/projects/asm/acp-demo/packages/pong-simulation/src/renderer/pygame_renderer.py:132\u001b[0m, in \u001b[0;36mPygameRenderer.render\u001b[0;34m(self, state, events, rewards, config, frame_index)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_surface()\u001b[38;5;241m.\u001b[39mblit(score_text, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmiddle_x \u001b[38;5;241m-\u001b[39m score_text\u001b[38;5;241m.\u001b[39mget_rect()\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m    131\u001b[0m pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "load_and_evaluate_models(\"play_against_self_opponent_3\", \"play_against_self_opponent_3\", self_env, env_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '.models/baseline/8/play_against_self_opponent_3.zip'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplay_against_self_opponent_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# slowly start rewarding for winning rounds\u001b[39;00m\n\u001b[1;32m      4\u001b[0m reward_config \u001b[38;5;241m=\u001b[39m RewardConfig(\n\u001b[1;32m      5\u001b[0m     win_round \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      6\u001b[0m     lose_round \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     endurance_penalty_multiplier \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n",
            "Cell \u001b[0;32mIn[8], line 28\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PPO:\n\u001b[0;32m---> 28\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     model\u001b[38;5;241m.\u001b[39mtensorboard_log \u001b[38;5;241m=\u001b[39m tb_log_dir\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
            "File \u001b[0;32m~/.cache/pants/named_caches/pex_root/venvs/s/6247a7b5/venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py:659\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    657\u001b[0m     get_system_info()\n\u001b[0;32m--> 659\u001b[0m data, params, pytorch_variables \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# Remove stored device information and replace with ours\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
            "File \u001b[0;32m~/.cache/pants/named_caches/pex_root/venvs/s/6247a7b5/venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:390\u001b[0m, in \u001b[0;36mload_from_zip_file\u001b[0;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_zip_file\u001b[39m(\n\u001b[1;32m    364\u001b[0m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath, io\u001b[38;5;241m.\u001b[39mBufferedIOBase],\n\u001b[1;32m    365\u001b[0m     load_data: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m     print_system_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    370\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (Tuple[Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], Optional[TensorDict], Optional[TensorDict]]):\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     load_path \u001b[38;5;241m=\u001b[39m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device(device\u001b[38;5;241m=\u001b[39mdevice)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.16/lib/python3.8/functools.py:875\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    873\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.cache/pants/named_caches/pex_root/venvs/s/6247a7b5/venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:234\u001b[0m, in \u001b[0;36mopen_path_str\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;129m@open_path\u001b[39m\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m io\u001b[38;5;241m.\u001b[39mBufferedIOBase:\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    that the path exists.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.16/lib/python3.8/functools.py:875\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    873\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.cache/pants/named_caches/pex_root/venvs/s/6247a7b5/venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:286\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    279\u001b[0m         path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# if opening was successful uses the identity function\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.16/lib/python3.8/functools.py:875\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    873\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.cache/pants/named_caches/pex_root/venvs/s/6247a7b5/venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:266\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    264\u001b[0m             path, suffix \u001b[38;5;241m=\u001b[39m newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 266\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/.cache/pants/named_caches/pex_root/venvs/s/6247a7b5/venv/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:258\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.16/lib/python3.8/pathlib.py:1222\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_closed()\n\u001b[0;32m-> 1222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m               \u001b[49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.16/lib/python3.8/pathlib.py:1078\u001b[0m, in \u001b[0;36mPath._opener\u001b[0;34m(self, name, flags, mode)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_opener\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, flags, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0o666\u001b[39m):\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# A stub for the opener argument to built-in open()\u001b[39;00m\n\u001b[0;32m-> 1078\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.models/baseline/8/play_against_self_opponent_3.zip'"
          ]
        }
      ],
      "source": [
        "model = load_model(\"play_against_self_opponent_3\")\n",
        "\n",
        "# slowly start rewarding for winning rounds\n",
        "reward_config = RewardConfig(\n",
        "    win_round = 10,\n",
        "    lose_round = -10,\n",
        "    paddle_hit = 10,\n",
        "    near_miss_multiplier = 0,\n",
        "    near_miss_exponent = 4,\n",
        "    near_miss_min_distance = height / 10,\n",
        "    survival_reward_multiplier = 0,\n",
        "    endurance_penalty_multiplier = -0,\n",
        ")\n",
        "\n",
        "env_config = EnvConfig(\n",
        "    paddle_l = player_paddle,\n",
        "    paddle_r = player_paddle,\n",
        "    width = width,\n",
        "    height = height,\n",
        ")\n",
        "\n",
        "self_env = PongEnv(env_config, reward_config)\n",
        "model.set_env(self_env)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(model_dir_for(\"attack_opponent\"))\n",
        "for i in range(500):\n",
        "    opponent = load_model(\"attack_opponent\")\n",
        "    self_env.set_opponent(ModelOpponent(opponent))\n",
        "    \n",
        "    learn(model, \"attack_opponent\", self_env, 10_000)\n",
        "    model.save(model_dir_for(\"attack_opponent\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(model_dir_for(\"attack_opponent\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_and_evaluate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattack_opponent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplay_against_self_opponent_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[8], line 50\u001b[0m, in \u001b[0;36mload_and_evaluate_models\u001b[0;34m(name_l, name_r, env, config, iterations)\u001b[0m\n\u001b[1;32m     47\u001b[0m env\u001b[38;5;241m.\u001b[39mdisable_training()\n\u001b[1;32m     48\u001b[0m model_l\u001b[38;5;241m.\u001b[39mset_env(env)\n\u001b[0;32m---> 50\u001b[0m \u001b[43mEvaluationRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygame_renderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/projects/asm/acp-demo/packages/pong-simulation/src/services/evaluation_runner.py:60\u001b[0m, in \u001b[0;36mEvaluationRunner.evaluate\u001b[0;34m(self, model, env, config, iterations)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Render the current state of the simulation, via the environment\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevents\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrewards\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m frame_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     65\u001b[0m result \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/projects/asm/acp-demo/packages/pong-simulation/src/renderer/pygame_renderer.py:132\u001b[0m, in \u001b[0;36mPygameRenderer.render\u001b[0;34m(self, state, events, rewards, config, frame_index)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_surface()\u001b[38;5;241m.\u001b[39mblit(score_text, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmiddle_x \u001b[38;5;241m-\u001b[39m score_text\u001b[38;5;241m.\u001b[39mget_rect()\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m    131\u001b[0m pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "load_and_evaluate_models(\"attack_opponent\", \"play_against_self_opponent_3\", self_env, env_config)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "29287708f5ac4062cbd3fc6f78e4cc0472b9f1dcb960699e48edd5b82bb44a9e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}